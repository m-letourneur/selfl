question,notes,id,score
Define what is  accuracy,"   The fraction of predictions that aclassification modelgot right. Inmulti-class classification, accuracy
is defined as follows:  Accuracy=CorrectPredictionsTotalNumberOfExamplesAccuracy = \frac{Correct\,Predictions} {Total\,Number\,Of\,Examples}  Inbinary classification, accuracy has
the following definition:  Accuracy=TruePositives+TrueNegativesTotalNumberOfExamplesAccuracy = \frac{True\,Positives + True\,Negatives} {Total\,Number\,Of\,Examples}  Seetrue positiveandtrue negative.  ",0,-1
Define what is activation function,"   A function (for example,ReLUorsigmoid)
that takes in the weighted sum of all of the inputs from the previous layer
and then generates and passes an output value (typically nonlinear) to the next
layer.  ",1,-1
Define what is  AdaGrad,"   A sophisticated gradient descent algorithm that rescales the
gradients of each parameter, effectively giving each parameter
an independentlearning rate. For a full explanation, seethis paper.  ",2,-1
Define what is  AUC (Area under the ROC Curve),"   An evaluation metric that considers all possibleclassification thresholds.  The Area Under theROC curveis the probability that a classifier
will be more confident that a randomly chosen positive example is actually
positive than that a randomly chosen negative example is positive. ",3,-1
Define what is  backpropagation,"   The primary algorithm for performinggradient descentonneural networks. First, the output values
of each node are calculated (and cached) in a forward pass.
Then, thepartial derivativeof the error with respect to each parameter is calculated in a backward
pass through the graph.  ",4,-1
Define what is  baseline,"   A simplemodelor heuristic used as reference point for comparing
how well a model is performing. A baseline helps model developers quantify
the minimal, expected performance on a particular problem.  ",5,-1
Define what is  batch,"   The set of examples used in one iteration (that is, onegradientupdate) ofmodel training.  ",6,-1
Define what is  batch size,"   The number of examples in abatch. For example, the batch size
ofSGDis 1, while the batch size of
amini-batchis usually between 10 and 1000. Batch size is
usually fixed during training and inference; however, TensorFlow does permit
dynamic batch sizes.  ",7,-1
Define what is  bias,"   An intercept or offset from an origin. Bias (also known as thebias term) is referred to asborw0in
machine learning models.  For example, bias is thebin the
following formula:  y′=b+w1x1+w2x2+…wnxny' = b + w_1x_1 + w_2x_2 + … w_nx_n  Not to be confused withprediction bias.  ",8,-1
Define what is  binary classification,"   A type of classification task that outputs one of two mutually
exclusive classes. For example, a machine learning model that evaluates
email messages and outputs either ""spam"" or ""not spam"" is a binary classifier.  ",9,-1
Define what is  binning,   Seebucketing.  ,10,-1
Define what is  bucketing,"   Converting a (usuallycontinuous) feature into
multiple binary features called buckets or bins, typically based on value
range. For example, instead of representing temperature as a single
continuous floating-point feature, you could chop ranges of temperatures
into discrete bins. Given temperature data sensitive to a tenth of a degree,
all temperatures between 0.0 and 15.0 degrees could be put into one bin,
15.1 to 30.0 degrees could be a second bin, and 30.1 to 50.0 degrees could
be a third bin. ",11,-1
Define what is  calibration layer,"   A post-prediction adjustment, typically to account forprediction bias. The adjusted predictions and
probabilities should match the distribution of an observed set of labels.  ",12,-1
Define what is  candidate sampling,"   A training-time optimization in which a probability is calculated for all
the positive labels, using, for example, softmax, but only for a random
sample of negative labels. For example, if we have an example labeledbeagleanddogcandidate sampling computes the predicted probabilities
and corresponding loss terms for thebeagleanddogclass outputs
in addition to a random subset of the remaining classes
(cat,lollipop,fence). The idea is that thenegative classescan learn from less frequent
negative reinforcement as long aspositive classesalways get proper positive
reinforcement, and this is indeed observed empirically. The motivation for
candidate sampling is a computational efficiency win from not computing
predictions for all negatives.  ",13,-1
Define what is  checkpoint,"   Data that captures the state of the variables of a model at a particular
time. Checkpoints enable exporting modelweights, as well
as performing training across multiple sessions. Checkpoints also enable
training to continue past errors (for example, job preemption). Note that
thegraphitself is not included in a checkpoint.  ",14,-1
Define what is  class,"   One of a set of enumerated target values for a label. For example, in abinary classificationmodel that detects
spam, the two classes arespamandnot spam.  In amulti-class classificationmodel that
identifies dog breeds, the classes would bepoodle,beagle,pug, and so
on.  ",15,-1
Define what is  class-imbalanced data set,"   Abinary classificationproblem in which thelabelsfor the two classes have significantly different
frequencies.  For example, a disease data set in which 0.0001 of examples
have positive labels and 0.9999 have negative labels is a class-imbalanced
problem, but a football game predictor in which 0.51 of examples label one
team winning and 0.49 label the other team winning isnota
class-imbalanced problem.  ",16,-1
Define what is  classification model,"   A type of machine learning model for distinguishing among two or more
discrete classes. For example, a natural language processing classification
model could determine whether an input sentence was in French, Spanish,
or Italian. Compare withregression model.  ",17,-1
Define what is  classification threshold,"   A scalar-value criterion that is applied to a model's predicted score in order
to separate thepositive classfrom thenegative
class.  Used when mappinglogistic regressionresults tobinary classification. For example, consider
a logistic regression model that determines the probability of a given email
message being spam. If the classification threshold is 0.9, then logistic
regression values above 0.9 are classified asspamand those below
0.9 are classified asnot spam.  ",18,-1
Define what is  confusion matrix,"   An NxN table that summarizes how successful aclassification model'spredictions were; that is,
the correlation between the label and the model's classification. One axis of
a confusion matrix is the label that the model predicted, and the other axis
is the actual label. N represents the number of classes. In abinary classificationproblem, N=2. For example,
here is a sample confusion matrix for a binary classification problem:  Tumor (predicted)Non-Tumor (predicted)Tumor (actual)181Non-Tumor (actual)6452  The preceding confusion matrix shows that of the 19 samples that actually had
tumors, the model correctly classified 18 as having tumors
(18 true positives), and incorrectly classified 1 as not having a tumor
(1 false negative). Similarly, of 458 samples that actually did not have
tumors, 452 were correctly classified (452 true negatives) and 6 were
incorrectly classified (6 false positives).  The confusion matrix of a multi-class confusion matrix can help you
determine mistake patterns. For example, a confusion matrix could reveal
that a model trained to recognize handwritten digits tends to mistakenly
predict 9 instead of 4, or 1 instead of 7.
The confusion matrix contains sufficient information to calculate a
variety of performance metrics, including precision and recall.  ",19,-1
Define what is  continuous feature,"   A floating-point feature with an infinite range of possible values.
Contrast withdiscrete feature.  ",20,-1
Define what is  convergence,"   Informally, often refers to a state reached during training in which traininglossand validation loss change very little or not at all
with each iteration after a certain number of iterations. In other words, a
model reaches convergence when additional training on the current data will
not improve the model. In deep learning, loss values sometimes stay constant
or nearly so for many iterations before finally descending, temporarily
producing a false sense of convergence.  See alsoearly stopping.  See alsoConvex Optimization by Boyd and Vandenberghe.  ",21,-1
Define what is  convex function,"   A function typically shaped approximately like the letter U or a bowl.
However, indegenerate cases,
a convex function is shaped like a line.
For example, the following are all convex functions:  L2lossLog LossL1regularizationL2regularization  Convex functions are popular loss functions.  That's because when a
minimum value exists (as is often the case), many variations ofgradient descentare guaranteed to find a
point close to the minimum point of the function. Similarly, many variations ofstochastic gradient descenthave a high probability
(though, not a guarantee) of finding a point close to the minimum.  The sum of two convex functions (for example,
L2loss + L1regularization) is a convex function.  Deep models are usuallynotconvex functions.  Remarkably, algorithms
designed for convex optimization tend to work reasonably well on deep
networks anyway, even though they rarely find a minimum.  ",22,-1
Define what is  cost,   Synonym forloss.  ,23,-1
Define what is  cross-entropy,"   A generalization ofLog Losstomulti-class classification problems. Cross-entropy
quantifies the difference between two probability distributions.  See alsoperplexity. ",24,-1
Define what is  data set,   A collection ofexamples.  ,25,-1
Define what is  decision boundary,"   The separator between classes learned by a model in abinary classormulti-class classification problems. For example,
in the following image representing a binary classification problem,
the decision boundary is the frontier between the orange class and
the blue class:    ",26,-1
Define what is  deep model,"   A type ofneural networkcontaining multiplehidden layers. Deep models rely on trainable
nonlinearities.  Contrast withwide model.  ",27,-1
Define what is  dense feature,"   Afeaturein which most values are non-zero, typically
aTensorof floating-point values. Contrast withsparse feature.  ",28,-1
Define what is  derived feature,   Synonym forsynthetic feature.  ,29,-1
Define what is  discrete feature,"   Afeaturewith a finite set of possible values. For example,
a feature whose values may only beanimal,vegetable, ormineralis a
discrete (or categorical) feature. Contrast withcontinuous feature.  ",30,-1
Define what is  dropout regularization,"   A form ofregularizationuseful in trainingneural networks. Dropout regularization works by
removing a random selection of a fixed number of the units in a network
layer for a single gradient step. The more units dropped out, the stronger
the regularization. This is analogous to training the network to emulate
an exponentially large ensemble of smaller networks. For full details, seeDropout: A Simple Way to Prevent Neural Networks from Overfitting.  ",31,-1
Define what is  dynamic model,"   Amodelthat is trained online in a continuously
updating fashion.  That is, data is continuously entering the model. ",32,-1
Define what is  early stopping,"   A method forregularizationthat involves ending
model trainingbeforetraining loss finishes decreasing. In early
stopping, you end model training when the loss on avalidation data setstarts to increase, that is, whengeneralizationperformance worsens.  ",33,-1
Define what is  embeddings,"   A categorical feature represented as a continuous-valued feature.
Typically, an embedding is a translation of a high-dimensional vector
into a low-dimensional space. For example, you can represent the words
in an English sentence in either of the following two ways:  As a million-element (high-dimensional)sparse vectorin which all elements are integers.
    Each cell in the vector represents a separate English word; the value in
    a cell represents the number of times that word appears in a sentence.
    Since a single English sentence is unlikely to contain more than 50 words,
    nearly every cell in the vector will contain a 0. The few cells that
    aren't 0 will contain a low integer (usually 1) representing the number of
    times that word appeared in the sentence.As a several-hundred-element (low-dimensional)dense vectorin which each element holds a
    floating-point valuebetween0 and 1.  In TensorFlow, embeddings are trained bybackpropagatinglossjust like any other parameter in aneural network.  ",34,-1
Define what is  empirical risk minimization (ERM),"   Choosing the model function that minimizes loss on the training set. Contrast
withstructural risk minimization.  ",35,-1
Define what is  ensemble,"   A merger of the predictions of multiplemodels. You can create an
ensemble via one or more of the following:  different initializationsdifferenthyperparametersdifferent overall structure  Deep and wide modelsare a kind of ensemble. ",36,-1
Define what is  Estimator,"   An instance of thetf.Estimatorclass, which encapsulates logic that builds
a TensorFlow graph and runs a TensorFlow session. You may create your own
Estimators (as describedhere)
or instantiatepre-made Estimatorscreated by
others.  ",37,-1
Define what is  example,   One row of a data set. An example contains one or morefeaturesand possibly alabel. See alsolabeled exampleandunlabeled example. ,38,-1
Define what is  false negative (FN),"   An example in which the model mistakenly predicted thenegative class. For example, the model
inferred that a particular email message was not spam
(the negative class), but that email message actually was spam.  ",39,-1
Define what is  false positive (FP),"   An example in which the model mistakenly predicted thepositive class. For example, the model inferred
that a particular email message was spam (the positive class), but that
email message was actually not spam.  ",40,-1
Define what is  false positive rate (FP rate),"   The x-axis in anROC curve. The FP rate is defined as follows:  FalsePositiveRate=FalsePositivesFalsePositives+TrueNegativesFalse\,Positive\,Rate = \frac{False\,Positives} {False\,Positives + True\,Negatives}  ",41,-1
Define what is  feature,   An input variable used in makingpredictions.  ,42,-1
Define what is  feature columns (FeatureColumns),"   A set of related features, such as the set of all possible countries in
which users might live. An example may have one or more features present
in a feature column.  Feature columns in TensorFlow also encapsulate metadata such as:  the feature's data typewhether a feature is fixed length or should be converted to an embedding  A feature column can contain a single feature.  ""Feature column"" is Google-specific terminology.
A feature column is referred to as a ""namespace"" in theVWsystem (at Yahoo/Microsoft),
or afield.  ",43,-1
Define what is  feature cross,"   Asynthetic featureformed by crossing (multiplying
or taking a Cartesian product of) individual features. Feature crosses help
represent nonlinear relationships.  ",44,-1
Define what is  feature engineering,"   The process of determining whichfeaturesmight be useful
in training a model, and then converting raw data from log files and other
sources into said features. In TensorFlow, feature engineering often means
converting raw log file entries totf.Exampleprotocol buffers.  See alsotf.Transform.  Feature engineering is sometimes calledfeature extraction.  ",45,-1
Define what is  feature set,"   The group offeatureyour machine learning model trains on.
For example, postal code, property size, and property condition might
comprise a simple feature set for a model that predicts housing prices.  ",46,-1
Define what is  feature spec,"   Describes the information required to extractfeaturesdata
from thetf.Exampleprotocol buffer. Because the
tf.Example protocol buffer is just a container for data, you must specify
the following:  the data to extract (that is, the keys for the features)the data type (for example, float or int)The length (fixed or variable)  TheEstimator APIprovides facilities for producing a
feature spec from a list ofFeatureColumns.  ",47,-1
Define what is  full softmax,   Seesoftmax. Contrast withcandidate sampling. ,48,-1
Define what is  generalization,"   Refers to your model's ability to make correct predictions on new,
previously unseen data as opposed to the data used to train the model.  ",49,-1
Define what is  generalized linear model,"   A generalization ofleast squares regressionmodels, which are based onGaussian noise, to other
types of models based on other types of noise,
such asPoisson noiseor
categorical noise. Examples of generalized linear models include:  logistic regressionmulti-class regressionleast squares regression  The parameters of a generalized linear model can be found throughconvex optimization.  Generalized linear models exhibit the following properties:  The average prediction of the optimal least squares regression model is
    equal to the average label on the training data.The average probability predicted by the optimal logistic regression
    model is equal to the average label on the training data.  The power of a generalized linear model is limited by its features. Unlike
a deep model, a generalized linear model cannot ""learn new features.""  ",50,-1
Define what is  gradient,"   The vector ofpartial derivativeswith respect to
all of the independent variables.  In machine learning, the gradient is the
the vector of partial derivatives of the model function.  The gradient points
in the direction of steepest ascent.  ",51,-1
Define what is  gradient clipping,"   Cappinggradientvalues before applying them. Gradient
clipping helps ensure numerical stability and preventsexploding gradients.  ",52,-1
Define what is  gradient descent,"   A technique to minimizelossby computing the gradients of
loss with respect to the model's parameters, conditioned on training data.
Informally, gradient descent iteratively adjusts parameters, gradually
finding the best combination ofweightsand bias to
minimize loss.  ",53,-1
Define what is  graph,"   In TensorFlow, a computation specification. Nodes in the graph
represent operations. Edges are directed and represent passing the result
of an operation
(aTensor) as an
operand to another operation. UseTensorBoardto visualize a graph. ",54,-1
Define what is  heuristic,"   A practical and nonoptimal solution to a problem, which is sufficient for
making progress or for learning from.  ",55,-1
Define what is  hidden layer,"   A synthetic layer in aneural networkbetween theinput layer(that is, the features) and theoutput layer(the prediction). A neural network
contains one or more hidden layers.  ",56,-1
Define what is  hinge loss,"   A family oflossfunctions forclassificationdesigned to find thedecision boundaryas distant as possible 
from each training example,
thus maximizing the margin between examples and the boundary.KSVMsuse hinge loss (or a related function, such as
squared hinge loss). For binary classification, the hinge loss function 
is defined as follows:  loss=max(0,1−(y′∗y))loss = max(0, 1 - (y' * y))  wherey'is the raw output of the classifier model:  y′=b+w1x1+w2x2+…wnxny' = b + w_1x_1 + w_2x_2 + … w_nx_n  andyis the true label, either -1 or +1.  Consequently, a plot of hinge loss vs. (y * y') looks as follows:    ",57,-1
Define what is  holdout data,"   Examplesintentionally not used (""held out"") during training.
Thevalidation data setandtest data setare examples of holdout data. Holdout data
helps evaluate your model's ability to generalize to data other than the
data it was trained on. The loss on the holdout set provides a better
estimate of the loss on an unseen data set than does the loss on the
training set.  ",58,-1
Define what is  hyperparameter,"   The ""knobs"" that you

tweak during successive runs of training a model. For example,learning rateis a hyperparameter.  Contrast withparameter. ",59,-1
Define what is independently and identically distributed (i.i.d),"   Data drawn from a distribution that doesn't change, and where each value
drawn doesn't depend on values that have been drawn previously. An i.i.d.
is theideal gasof machine
learning—a useful mathematical construct but almost never exactly found
in the real world. For example, the distribution of visitors to a web page
may be i.i.d. over a brief window of time; that is, the distribution doesn't
change during that brief window and one person's visit is generally
independent of another's visit. However, if you expand that window of time,
seasonal differences in the web page's visitors may appear.  ",60,-1
Define what is  inference,"   In machine learning, often refers to the process of making predictions by
applying the trained model tounlabeled examples.
In statistics, inference refers to the process of fitting the parameters
of a distribution conditioned on some observed data. (See theWikipedia article on statistical inference.)  ",61,-1
Define what is  input layer,"   The first layer (the one that receives the input data) in
aneural network.  ",62,-1
Define what is  instance,   Synonym forexample.  ,63,-1
Define what is  inter-rater agreement,"   A measurement of how often human raters agree when doing a task.
If raters disagree, the task instructions may need to be improved.
Also sometimes calledinter-annotator agreementorinter-rater reliability.  See alsoCohen's kappa,
which is one of the most popular inter-rater agreement measurements. ",64,-1
Define what is Kernel Support Vector Machines (KSVMs),"   A classification algorithm that seeks to maximize the margin betweenpositiveandnegative classesby mapping input data vectors 
to a higher dimensional space.  For example, consider a classification 
problem in which the input data
set consists of a hundred features. In order to maximize the margin between
positive and negative classes, KSVMs could internally map those features into
a million-dimension space.  KSVMs uses a loss function calledhinge loss. ",65,-1
Define what is  L,"   Lossfunction based on the absolute value of the difference
between the values that a model is predicting and the actual values of
thelabels. L1loss is less sensitive to outliers
thanL2loss.  ",66,-1
Define what is  L,"   A type ofregularizationthat penalizes weights
in proportion to the sum of the absolute values of the weights. In models
relying onsparse features, L1regularization helps drive the weights of irrelevant or barely relevant
features to exactly 0, which removes those features from the model.
Contrast withL2regularization.  ",67,-1
Define what is  L,   Seesquared loss.  ,68,-1
Define what is  L,"   A type ofregularizationthat penalizes weights
in proportion to the sum of thesquaresof the weights.
L2regularization helps drive outlier weights (those with
high positive or low negative values) closer to 0 but not quite to 0.
(Contrast withL1 regularization.)
L2regularization always improves generalization in linear models.  ",69,-1
Define what is  label,"   In supervised learning, the ""answer"" or ""result"" portion of anexample. Each example in a labeled data set consists of one or
more features and a label. For instance, in a housing data set, the features
might include the number of bedrooms, the number of bathrooms, and the age
of the house, while the label might be the house's price.
in a spam detection dataset, the features might include the subject line, the
sender, and the email message itself, while the label would probably be either
""spam"" or ""not spam.""  ",70,-1
Define what is  labeled example,"   An example that containsfeaturesand alabel. In supervised training, models learn from labeled
examples.  ",71,-1
Define what is  lambda,"   Synonym forregularization rate.  (This is an overloaded term. Here we're focusing on the term's
definition withinregularization.)  ",72,-1
Define what is  layer,"   A set ofneuronsin aneural networkthat process a set of input
features, or the output of those neurons.  Also, an abstraction in TensorFlow. Layers are Python
functions that takeTensorsand configuration options
as input and produce other tensors as output. Once the necessary Tensors
have been composed, the user can convert the result into anEstimatorvia a model function.  ",73,-1
Define what is  learning rate,"   A scalar used to train a model via gradient descent. During each iteration,
thegradient descentalgorithm multiplies the
learning rate by the gradient.  The resulting product is called thegradient step.  Learning rate is a keyhyperparameter.  ",74,-1
Define what is  least squares regression,   A linear regression model trained by minimizingL2Loss.  ,75,-1
Define what is  linear regression,"   A type ofregression modelthat outputs a continuous
value from a linear combination of input features.  ",76,-1
Define what is  logistic regression,"   A model that generates a probability for each possible discrete label value in
classification problems by applying asigmoid functionto a linear prediction. Although logistic regression is often used inbinary classificationproblems, it can also be
used inmulti-classclassification problems (where it
becomes calledmulti-class logistic regressionormultinomial regression).  ",77,-1
Define what is  Log Loss,   Thelossfunction used in binarylogistic regression.  ,78,-1
Define what is  loss,"   A measure of how far a model'spredictionsare from itslabel. Or, to phrase it more pessimistically, a measure of
how bad the model is. To determine this value, a model must define a loss
function. For example, linear regression models typically usemean squared errorfor a loss function,
while logistic regression models useLog Loss. ",79,-1
Define what is  machine learning,"   A program or system that builds (trains) a predictive model from input data.
The system uses the learned model to make useful predictions from new
(never-before-seen) data drawn from the same distribution as the one used to
train the model. Machine learning also refers to the field of study concerned
with these programs or systems.  ",80,-1
Define what is  Mean Squared Error (MSE),"   The average squared loss per example. MSE is calculated by dividing thesquared lossby the number ofexamples. The values thatTensorFlow Playgrounddisplays for
""Training loss"" and ""Test loss"" are MSE.  ",81,-1
Define what is  metric,"   A number that you care about. May or may not be directly optimized in a
machine-learning system. A metric that your system tries to optimize is
called anobjective.  ",82,-1
Define what is  mini-batch,"   A small, randomly selected subset of the entire batch ofexamplesrun together in a single iteration of training
or inference. Thebatch sizeof a mini-batch is usually
between 10 and 1,000. It is much more efficient to calculate the loss on a
mini-batch than on the full training data.  ",83,-1
Define what is  mini-batch stochastic gradient descent (SGD),"   Agradient descentalgorithm that usesmini-batches. In other words, mini-batch SGD estimates the
gradient based on a small subset of the training data.Vanilla SGDuses a mini-batch of size 1.  ",84,-1
Define what is  ML,   Abbreviation formachine learning.  ,85,-1
Define what is  model,"   The representation of what an ML system has learned from the training data.
This is an overloaded term, which can have either of the following two
related meanings:  TheTensorFlowgraph that expresses the structure of
    how a prediction will be computed.The particular weights and biases of that TensorFlow graph, which are
    determined bytraining.  ",86,-1
Define what is  model training,   The process of determining the bestmodel.  ,87,-1
Define what is  Momentum,"   A sophisticated gradient descent algorithm in which a learning step depends
not only on the derivative in the current step, but also on the derivatives
in the step(s) that immediately preceded it. Momentum involves computing an
exponentially weighted moving average of the gradients over time, analogous
to momentum in physics.  Momentum sometimes prevents learning from getting
stuck in local minima.  ",88,-1
Define what is  multi-class,"   Classification problems that distinguish among more than two classes. For
example, there are approximately 128 species of maple trees, so a model
that categorized maple tree species would be multi-class. Conversely, a
model that divided emails into only two categories (spamandnot spam)
would be abinary classification model. ",89,-1
Define what is  NaN trap,"   When one number in your model becomes aNaNduring training, which causes
many or all other numbers in your model to eventually become a NaN.  NaN is an abbreviation for ""Not a Number.""  ",90,-1
Define what is  negative class,"   Inbinary classification, one class is
termed positive and the other is termed negative. The positive class is
the thing we're looking for and the negative class is the other possibility.
For example, the negative class in a medical test might be ""not tumor.""
The negative class in an email classifier might be ""not spam.""
See alsopositive class.  ",91,-1
Define what is  neural network,"   A model that, taking inspiration from the brain, is composed of layers
(at least one of which ishidden) consisting of
simple connected units orneuronsfollowed by nonlinearities.  ",92,-1
Define what is  neuron,"   A node in aneural network, typically taking in
multiple input values and generating one output value. The neuron calculates
the output value by applying anactivation function(nonlinear transformation)
to a weighted sum of input values.  ",93,-1
Define what is  normalization,"   The process of converting an actual range of values into a standard range
of values, typically -1 to +1 or 0 to 1. For example, suppose the natural
range of a certain feature is 800 to 6,000. Through subtraction and division,
you can normalize those values into the range -1 to +1.  See alsoscaling.  ",94,-1
Define what is  numpy,"   Anopen-source math librarythat provides
efficient array operations in Python.pandasis built
on numpy. ",95,-1
Define what is  objective,   A metric that your algorithm is trying to optimize.  ,96,-1
Define what is  offline inference,"   Generating a group ofpredictions, storing those
predictions, and then retrieving those predictions on demand. Contrast
withonline inference.  ",97,-1
Define what is  one-hot encoding,"   A sparse vector in which:  One element is set to 1.All other elements are set to 0.  One-hot encoding is commonly used to represent strings or identifiers that
have a finite set of possible values. For example, suppose a given botany
data set chronicles 15,000 different species, each denoted with a unique
string identifier. As part of feature engineering, you'll probably encode
those string identifiers as one-hot vectors in which the vector has a size
of 15,000.  ",98,-1
Define what is  one-vs.-all,"   Given a classification problem with N possible solutions, a one-vs.-all
solution consists of N separatebinary classifiers—one binary classifier for
each possible outcome. For example, given a model that classifies examples
as animal, vegetable, or mineral, a one-vs.-all solution would provide the
following three separate binary classifiers:  animal vs. not animalvegetable vs. not vegetablemineral vs. not mineral  ",99,-1
Define what is  online inference,   Generatingpredictionson demand. Contrast withoffline inference.  ,100,-1
Define what is  Operation (op),"   A node in the TensorFlow graph. In TensorFlow, any procedure that creates,
manipulates, or destroys aTensoris an operation. For
example, a matrix multiply is an operation that takes two Tensors as
input and generates one Tensor as output.  ",101,-1
Define what is  optimizer,"   A specific implementation of thegradient descentalgorithm. TensorFlow's base class for optimizers istf.train.Optimizer.
Different optimizers (subclasses oftf.train.Optimizer) account for
concepts such as:  momentum(Momentum)update frequency
    (AdaGrad= ADAptive GRADient descent;Adam= ADAptive with Momentum; RMSProp)sparsity/regularization
    (Ftrl)more complex math
    (Proximal,
    and others)  You might even imagine anNN-driven optimizer.  ",102,-1
Define what is  outliers,"   Values distant from most other values. In machine learning, any of the
following are outliers:  Weightswith high absolute values.Predicted values relatively far away from the actual values.Input data whose values are more than roughly 3 standard deviations
    from the mean.  Outliers often cause problems in model training.  ",103,-1
Define what is  output layer,"   The ""final"" layer of a neural network. The layer containing the answer(s).  ",104,-1
Define what is  overfitting,"   Creating a model that matches thetraining dataso
closely that the model fails to make correct predictions on new data. ",105,-1
Define what is  pandas,"   A column-oriented data analysis API. Many ML frameworks, including
TensorFlow, support pandas data structures as input. Seepandas documentation.  ",106,-1
Define what is  parameter,"   A variable of a model that the ML system trains on its own. For example,weightsare parameters whose values the ML system gradually
learns through successive training iterations. Contrast withhyperparameter.  ",107,-1
Define what is  Parameter Server (PS),"   A job that keeps track of a model'sparametersin a
distributed setting.  ",108,-1
Define what is  parameter update,"   The operation of adjusting a model'sparametersduring
training, typically within a single iteration ofgradient descent.  ",109,-1
Define what is  partial derivative,"   A derivative in which all but one of the variables is considered a constant.
For example, the partial derivative off(x, y)with respect toxis the
derivative offconsidered as a function ofxalone (that is, keepingyconstant). The partial derivative offwith respect toxfocuses only on
howxis changing and ignores all other variables in the equation.  ",110,-1
Define what is  partitioning strategy,   The algorithm by which variables are divided acrossparameter servers.  ,111,-1
Define what is  performance,"   Overloaded term with the following meanings:  The traditional meaning within software engineering. Namely: How fast
    (or efficiently) does this piece of software run?The meaning within ML. Here, performance answers the following question:
    How correct is thismodel? That is, how good are the
    model's predictions?  ",112,-1
Define what is  perplexity,"   One measure of how well amodelis accomplishing its task.
For example, suppose your task is to read the first few letters of a word
a user is typing on a smartphone keyboard, and to offer a list of possible
completion words. Perplexity, P, for this task is approximately the number
of guesses you need to offer in order for your list to contain the actual
word the user is trying to type.  Perplexity is related tocross-entropyas follows:  P=2−crossentropyP= 2^{-cross entropy}  ",113,-1
Define what is  pipeline,"   The infrastructure surrounding a machine learning algorithm. A pipeline
includes gathering the data, putting the data into training data files,
training one or more models, and exporting the models to production.  ",114,-1
Define what is  positive class,"   Inbinary classification, the two possible
classes are labeled as positive and negative. The positive outcome is the
thing we're testing for. (Admittedly, we're simultaneously testing for
both outcomes, but play along.) For example, the positive class in a
medical test might be ""tumor."" The positive class in an email classifier
might be ""spam.""  Contrast withnegative class.  ",115,-1
Define what is  precision,"   A metric forclassification models. Precision
identifies the frequency with which a model was correct when predicting thepositive class. That is:  Precision=TruePositivesTruePositives+FalsePositivesPrecision = \frac{True\,Positives} {True\,Positives + False\,Positives}  ",116,-1
Define what is  prediction,   A model's output when provided with an inputexample.  ,117,-1
Define what is  prediction bias,   A value indicating how far apart the average ofpredictionsis from the average oflabelsin the data set.  ,118,-1
Define what is  pre-made Estimator,"   AnEstimatorthat someone has already built.
TensorFlow provides several pre-made Estimators, includingDNNClassifier,DNNRegressor, andLinearClassifier.  You may build your own
pre-made Estimators by followingthese instructions.  ",119,-1
Define what is  pre-trained model,"   Models or model components (such asembeddings) that have
been already been trained. Sometimes, you'll feed pre-trained embeddings
into aneural network. Other times, your model will
train the embeddings itself rather than rely on the pre-trained embeddings.  ",120,-1
Define what is  prior belief,"   What you believe about the data before you begin training on it. For
example,L2regularizationrelies on
a prior belief thatweightsshould be small and normally
distributed around zero. ",121,-1
Define what is  queue,"   A TensorFlowOperationthat implements a queue data
structure. Typically
used in I/O. ",122,-1
Define what is  rank,"   Overloaded term in ML that can mean either of the following:  The number of dimensions in aTensor. For instance,
    a scalar has rank 0, a vector has rank 1, and a matrix has rank 2.The ordinal position of a class in an ML problem that categorizes
    classes from highest to lowest. For example, a behavior ranking
    system could rank a dog's rewards from highest (a steak) to
    lowest (wilted kale).  ",123,-1
Define what is  rater,"   A human who provideslabelsinexamples.
Sometimes called an ""annotator.""  ",124,-1
Define what is  recall,"   A metric forclassification modelsthat answers
the following question: Out of all the possible positive labels, how many
did the model correctly identify? That is:  Recall=TruePositivesTruePositives+FalseNegativesRecall = \frac{True\,Positives} {True\,Positives + False\,Negatives}  ",125,-1
Define what is  Rectified Linear Unit (ReLU),"   Anactivation functionwith the following rules:  If input is negative or zero, output is 0.If input is positive, output is equal to input.  ",126,-1
Define what is  regression model,"   A type of model that outputs continuous (typically, floating-point) values.
Compare withclassification models, which
output discrete values, such as ""day lily"" or ""tiger lily.""  ",127,-1
Define what is  regularization,"   The penalty on a model's complexity. Regularization helps preventoverfitting. Different kinds of regularization include:  L1regularizationL2regularizationdropout regularizationearly stopping(this is not a formal
    regularization method, but can effectively limit overfitting)  ",128,-1
Define what is  regularization rate,"   A scalar value, represented as lambda, specifying the relative importance
of the regularization function. The following simplifiedlossequation shows the regularization rate's influence:  minimize(loss function +λ(regularization function))\text{minimize(loss function + }\lambda\text{(regularization function))}  Raising the regularization rate reducesoverfittingbut may make the model lessaccurate.  ",129,-1
Define what is  representation,   The process of mapping data to usefulfeatures.  ,130,-1
Define what is  ROC (receiver operating characteristic) Curve,   A curve oftrue positive ratevs.false positive rateat differentclassification thresholds. See alsoAUC.  ,131,-1
Define what is  root directory,"   The directory you specify for hosting subdirectories of the TensorFlow
checkpoint and events files of multiple models.  ",132,-1
Define what is  Root Mean Squared Error (RMSE),   The square root of theMean Squared Error. ,133,-1
Define what is  Saver,   ATensorFlow objectresponsible for saving model checkpoints.  ,134,-1
Define what is  scaling,"   A commonly used practice infeature engineeringto tame a feature's range of values to match the range of other features in
the data set. For example, suppose that you want all floating-point features
in the data set to have a range of 0 to 1. Given a particular feature's
range of 0 to 500, you could scale that feature by dividing each value
by 500.  See alsonormalization.  ",135,-1
Define what is  scikit-learn,   A popular open-source ML platform. Seewww.scikit-learn.org.  ,136,-1
Define what is  sequence model,"   A model whose inputs have a sequential dependence. For example, predicting
the next video watched from a sequence of previously watched videos.  ",137,-1
Define what is  session,"   Maintains state (for example, variables) within a TensorFlow program.  ",138,-1
Define what is  sigmoid function,"   A function that maps logistic or multinomial regression output (log odds) to
probabilities, returning a value between 0 and 1.  The sigmoid function has
the following formula:  y=11+e−σy = \frac{1}{1 + e^{-\sigma}}  whereσ\sigmainlogistic regressionproblems
is simply:  σ=b+w1x1+w2x2+…wnxn\sigma = b + w_1x_1 + w_2x_2 + … w_nx_n  In other words, the sigmoid function convertsσ\sigmainto a probability
between 0 and 1.  In someneural networks, the sigmoid function acts as
theactivation function.  ",139,-1
Define what is  softmax,"   A function that provides probabilities for each possible class in amulti-class classification model. The probabilities add up
to exactly 1.0. For example, softmax might determine that the probability of a
particular image being a dog at 0.9, a cat at 0.08, and a horse at 0.02.
(Also calledfull softmax.)  Contrast withcandidate sampling.  ",140,-1
Define what is  sparse feature,"   Featurevector whose values are predominately zero or empty.
For example, a vector containing a single 1 value and a million 0 values is
sparse. As another example, words in a search query could also be a
sparse feature—there are many possible words in a given language, but only a
few of them occur in a given query.  Contrast withdense feature.  ",141,-1
Define what is  squared loss,"   Thelossfunction used inlinear regression.  (Also known asL2Loss.) This function calculates the squares of
the difference between a model's predicted value for a labeledexampleand the actual value of thelabel.
Due to squaring, this loss function amplifies the influence of bad predictions.
That is, squared loss reacts more strongly to outliers
thanL1loss.  ",142,-1
Define what is  static model,   A model that is trained offline.  ,143,-1
Define what is  stationarity,"   A property of data in a data set, in which the data distribution stays constant
across one or more dimensions. Most commonly, that dimension is time, meaning
that data exhibiting stationarity doesn't change over time. For example, data
that exhibits stationarity doesn't change from September to December.  ",144,-1
Define what is  step,   A forward and backward evaluation of onebatch.  ,145,-1
Define what is  step size,   Synonym forlearning rate.  ,146,-1
Define what is  stochastic gradient descent (SGD),"   Agradient descentalgorithm in which the batch size
is one. In other words, SGD relies on a single example chosen uniformly at
random from a data set to calculate an estimate of the gradient at each step.  ",147,-1
Define what is  structural risk minimization (SRM),"   An algorithm that balances two goals:  The desire to build the most predictive model (for example, lowest loss).The desire to keep the model as simple as possible (for example, strong
    regularization).  For example, a model function that minimizes loss+regularization on the
training set is a structural risk minimization algorithm.  For more information, seehttp://www.svms.org/srm/.  Contrast withempirical risk minimization.  ",148,-1
Define what is  summary,"   In TensorFlow, a value or set of values calculated at a particularstep, usually used for tracking model metrics during training.  ",149,-1
Define what is  supervised machine learning,"   Training amodelfrom input data and its correspondinglabels. Supervised machine learning is analogous to a student
learning a subject by studying a set of questions and their corresponding
answers.  After mastering the mapping between questions and answers, the
student can then provide answers to new (never-before-seen) questions on
the same topic.  Compare withunsupervised machine learning.  ",150,-1
Define what is  synthetic feature,"   Afeaturethat is not present among the input features, but is
derived from one or more of them. Kinds of synthetic features include the
following:  Multiplying one feature by itself or by other feature(s). (These are
    termedfeature crosses.)Dividing one feature by a second feature.Bucketinga continuous feature into range bins.  Features created bynormalizingorscalingalone are not considered synthetic features. ",151,-1
Define what is  target,   Synonym forlabel.  ,152,-1
Define what is  Tensor,"   The primary data structure in TensorFlow programs. Tensors are N-dimensional
(where N could be very large) data structures, most commonly scalars, vectors,
or matrices. The elements of a Tensor can hold integer, floating-point,
or string values.  ",153,-1
Define what is  Tensor Processing Unit (TPU),"   An ASIC (application-specific integrated circuit) that optimizes the performance
of TensorFlow programs.  ",154,-1
Define what is  Tensor rank,   Seerank.  ,155,-1
Define what is  Tensor shape,"   The number of elements aTensorcontains in various dimensions.
For example, a [5, 10] Tensor has a shape of 5 in one dimension and 10
in another.  ",156,-1
Define what is  Tensor size,"   The total number of scalars aTensorcontains. For example, a
[5, 10] Tensor has a size of 50.  ",157,-1
Define what is  TensorBoard,"   The dashboard that displays the summaries saved during the execution of one or
more TensorFlow programs.  ",158,-1
Define what is  TensorFlow,"   A large-scale, distributed, machine learning platform. The term also refers to
the base API layer in the TensorFlow stack, which supports general computation
on dataflow graphs.  Although TensorFlow is primarily used for machine learning, you may also use
TensorFlow for non-ML tasks that require numerical computation using
dataflow graphs.  ",159,-1
Define what is  TensorFlow Playground,"   A program that visualizes how differenthyperparametersinfluence model
(primarily neural network) training.
Go tohttp://playground.tensorflow.orgto experiment with TensorFlow Playground.  ",160,-1
Define what is  TensorFlow Serving,   A platform to deploy trained models in production.  ,161,-1
Define what is  test set,   The subset of the data set that you use to test yourmodelafter the model has gone through initial vetting by the validation set. Contrast withtraining setandvalidation set.  ,162,-1
Define what is  tf.Example,   A standardprotocol bufferfor describing input data for machine learning model training or inference.  ,163,-1
Define what is  training,"   The process of determining the idealparameterscomprising
a model.  ",164,-1
Define what is  training set,   The subset of the data set used to train a model.  Contrast withvalidation setandtest set.  ,165,-1
Define what is  true negative (TN),"   An example in which the modelcorrectlypredicted thenegative class. For example, the model inferred that
a particular email message was not spam, and that email message really was
not spam.  ",166,-1
Define what is  true positive (TP),"   An example in which the modelcorrectlypredicted thepositive class. For example, the model inferred that
a particular email message was spam, and that email message really was spam.  ",167,-1
Define what is  true positive rate (TP rate),"   Synonym forrecall. That is:  TruePositiveRate=TruePositivesTruePositives+FalseNegativesTrue\,Positive\,Rate = \frac{True\,Positives} {True\,Positives + False\,Negatives}  True positive rate is the y-axis in anROC curve. ",168,-1
Define what is  unlabeled example,"   An example that containsfeaturesbut nolabel.
Unlabeled examples are the input toinference. In
semi-supervised and unsupervised learning, unlabeled examples are used
during training.  ",169,-1
Define what is  unsupervised machine learning,"   Training amodelto find patterns in a data set, typically an
unlabeled data set.  The most common use of unsupervised machine learning is to cluster data
into groups of similar examples. For example, an unsupervised machine
learning algorithm can cluster songs together based on various properties
of the music. The resulting clusters can become an input to other machine
learning algorithms (for example, to a music recommendation service).
Clustering can be helpful in domains where true labels are hard to obtain.
For example, in domains such as anti-abuse and fraud, clusters can help
humans better understand the data.  Another example of unsupervised machine learning isprincipal component analysis
(PCA).
For example, applying PCA on a
data set containing the contents of millions of shopping carts might reveal
that shopping carts containing lemons frequently also contain antacids.  Compare withsupervised machine learning. ",170,-1
Define what is  validation set,"   A subset of the data set—disjunct from the training set—that you
use to adjusthyperparameters.  Contrast withtraining setandtest set. ",171,-1
Define what is  weight,"   A coefficient for afeaturein a linear model, or an edge
in a deep network. The goal of training a linear model is to determine
the ideal weight for each feature. If a weight is 0, then its corresponding
feature does not contribute to the model.  ",172,-1
